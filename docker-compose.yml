services:
  # OpenWebUI service
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "80:3000"
    environment:
      - HOST=0.0.0.0
      - PORT=3000
      - WEBUI_AUTH_ENABLED=true
      - WEBUI_DB_BACKEND=postgres
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DATABASE=openwebui
      - DEFAULT_MODEL=gpt-4o
      - OPENAI_API_KEY=sk-litellm-master-key-123456
      - OPENAI_API_BASE_URL=http://litellm:4000/v1
      - OPENAI_API_MODELS=gpt-4,gpt-4o
      - ENABLE_SIGNUP=true
      - ENABLE_OAUTH_SIGNUP=true
      - ENABLE_LOGIN_FORM=false
      - WEBUI_ALLOW_PASSWORD_RESET=true
      - WEBUI_REGISTRATION_ENABLED=true
      - WEBUI_SHOW_REGISTRATION=true
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - GOOGLE_AUTH_ENABLED=true
      - ALLOWED_EMAIL_DOMAIN=*
      - GOOGLE_AUTO_REGISTER=true
    depends_on:
      litellm:
        condition: service_started
      postgres:
        condition: service_healthy
    volumes:
      - openwebui_data:/app/backend/data
    restart: unless-stopped


  # LiteLLM Proxy service
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    ports:
      - "8000:4000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - PORT=4000
      - MODEL_TYPE=openai
      - LITELLM_MASTER_KEY=sk-litellm-master-key-123456
      - LITELLM_SALT_KEY="semUmsej7yCU4XFEuegPB2Mj"
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/litellm
      - STORE_MODEL_IN_DB=True
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MCP_API_KEY=insight-mesh-mcp-abc-123
      - PYTHONPATH=/app
      - JWT_SECRET_KEY=your-super-secret-jwt-key-123  # Added JWT secret key
    volumes:
      - ./config/litellm_config.yaml:/app/config.yaml
      - ./rag_pipeline:/app/rag_pipeline
    command: ["--config", "/app/config.yaml", "--detailed_debug"]
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  # PostgreSQL Database
  postgres:
    image: postgres:14
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=litellm
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    
  # Redis for LiteLLM caching
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    
  # Elasticsearch for vector search
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.4
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    restart: unless-stopped

  # Neo4j for graph database
  neo4j:
    image: neo4j:5.13.0
    environment:
      - NEO4J_AUTH=neo4j/password
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    restart: unless-stopped

  mcp:
    build:
      context: ./mcp-server
      dockerfile: Dockerfile
    environment:
      - MCP_API_KEY=insight-mesh-mcp-abc-123  # Set explicit value instead of env var
      - JWT_SECRET_KEY=your-super-secret-jwt-key-123  # Added JWT secret key
      - DB_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/openwebui
      - REDIS_URL=redis://redis:6379/0
      - ELASTICSEARCH_HOST=elasticsearch
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=password
    ports:
      - "9090:8000"
    depends_on:
      - postgres
      - redis
      - elasticsearch
      - neo4j
    restart: unless-stopped

  slack-bot:
    build:
      context: ./slack-bot
      dockerfile: Dockerfile
    environment:
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      # SLACK_APP_TOKEN is only needed for Socket Mode in the slack-bot service
      - SLACK_APP_TOKEN=${SLACK_APP_TOKEN}
      - LLM_API_URL=http://litellm:8000/v1
      - LLM_API_KEY=sk-litellm-master-key-123456  # Updated to use master key
      - LLM_MODEL=gpt-4
    depends_on:
      - litellm
      - mcp
    restart: unless-stopped

volumes:
  openwebui_data:
  postgres_data:  # Persistent volume for PostgreSQL data
  redis_data:  # Persistent volume for Redis data
  elasticsearch_data:
  neo4j_data:  # Persistent volume for Neo4j data
  neo4j_logs:  # Persistent volume for Neo4j logs
